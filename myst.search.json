{"version":"1","records":[{"hierarchy":{"lvl1":"Intake Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Intake Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers using and creating Intake catalogs to access data.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Motivation"},"content":"This cookbook will help simplify the way you access and share data in your research. You will learn to access data using Intake catalogs and create Intake catalogs to make your data available to others.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Authors"},"content":"James Morley","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections - “Introduction to Intake” and “Creating Intake Catalogs.”","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"About HRRR","lvl2":"Structure"},"type":"lvl3","url":"/#about-hrrr","position":10},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"About HRRR","lvl2":"Structure"},"content":"High-Resolution Rapid Refresh (HRRR) is a atmospheric model maintained by \n\nNOAA. As stated on NOAA’s \n\nwebsite\n\nThe HRRR is a NOAA real-time 3-km resolution, hourly updated, cloud-resolving, convection-allowing atmospheric model, initialized by 3km grids with 3km radar assimilation. Radar data is\nassimilated in the HRRR every 15 min over a 1-h period adding further detail to that provided by the hourly data assimilation from the 13km radar-enhanced Rapid Refresh.\n\nThroughout this cookbook we use a subset of HRRR data maintained by Mesowest on AWS S3 object storage.","type":"content","url":"/#about-hrrr","position":11},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Introduction to Intake","lvl2":"Structure"},"type":"lvl3","url":"/#introduction-to-intake","position":12},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Introduction to Intake","lvl2":"Structure"},"content":"This section describes how to use intake catalogs to access data. It shows how to find information about catalog entries, how to set user parameters, and how to use intake with Dask.","type":"content","url":"/#introduction-to-intake","position":13},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Creating Intake Catalogs","lvl2":"Structure"},"type":"lvl3","url":"/#creating-intake-catalogs","position":14},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Creating Intake Catalogs","lvl2":"Structure"},"content":"This section walks you through the process of creating your own Intake catalogs to access Mesowest’s HRRR data.","type":"content","url":"/#creating-intake-catalogs","position":15},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":16},{"hierarchy":{"lvl1":"Intake Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":17},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":18},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":19},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":20},{"hierarchy":{"lvl1":"Intake Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/intake-cookbook repository: git clone https://github.com/ProjectPythia/intake-cookbook.git\n\nMove into the intake-cookbook directorycd intake-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate intake-cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":21},{"hierarchy":{"lvl1":"Creating Intake Catalogs"},"type":"lvl1","url":"/notebooks/creating-catalogs","position":0},{"hierarchy":{"lvl1":"Creating Intake Catalogs"},"content":"\n\n","type":"content","url":"/notebooks/creating-catalogs","position":1},{"hierarchy":{"lvl1":"Creating Intake Catalogs"},"type":"lvl1","url":"/notebooks/creating-catalogs#creating-intake-catalogs","position":2},{"hierarchy":{"lvl1":"Creating Intake Catalogs"},"content":"\n\n\n\n","type":"content","url":"/notebooks/creating-catalogs#creating-intake-catalogs","position":3},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/creating-catalogs#overview","position":4},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Overview"},"content":"In the last lesson we learned to use Intake catalogs to simplify the process of accessing research data. In this lesson we will walk through the steps of creating a catalog for your research data by recreating the catalog in the previous lesson.\n\nCreating an Intake catalog\n\nDocumenting your data source\n\nShare your catalog on Github.\n\n","type":"content","url":"/notebooks/creating-catalogs#overview","position":5},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/creating-catalogs#prerequisites","position":6},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Intake\n\nNecessary\n\n\n\nUnderstanding of yaml\n\nNecessary\n\n\n\nGetting Started with Github\n\nNecessary\n\n\n\nIntro to Pandas\n\nHelpful\n\n\n\nTime to learn: 45 minutes\n\n\n\n","type":"content","url":"/notebooks/creating-catalogs#prerequisites","position":7},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/creating-catalogs#imports","position":8},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Imports"},"content":"\n\nimport intake\nimport intake_xarray\nimport intake_markdown\nimport requests\nimport aiohttp\nimport s3fs\nimport yaml\nimport json\nimport datetime\nimport os\n\n","type":"content","url":"/notebooks/creating-catalogs#imports","position":9},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Setting up the Environment"},"type":"lvl2","url":"/notebooks/creating-catalogs#setting-up-the-environment","position":10},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Setting up the Environment"},"content":"By the end of this tutorial we will have created a git repository that we can host on Github to share our catalog.\n\nStart by \n\ncreating a Github repository called “intake-demo”, and then clone the repository to your local machine. Be sure to replace path/to/Github/repository with the name of the repository you just made in the following command.git clone path/to/Github/repository\n\nIntake catalogs can be a simple yaml file. We can create the yaml file programmatically by converting nested python dictionaries to yaml. A Intake catalog has two main parts metadata and sources. The metadata can be arbitrary with a few exceptions. The sources section is a mapping between a data source name and its properties. For more information about Intake catalogs, see Intake’s \n\ndocumentation\n\ndescription = \"Catalog containing Mesowest's HRRR data. See readme source for more information.\"\n\ncatalog = {'metadata': {'version': 1,\n                       'description': description},\n           'sources': {}}\n\nos.makedirs(\"intake-demo\", exist_ok=True) #only needed for building this notebook\nwith open('intake-demo/catalog.yml', 'w') as f:\n    yaml.dump(catalog, f)\n\nYou will now notice a new file in your “intake-demo” directory called “catalog.yml” with the following contents.\n\nwith open('intake-demo/catalog.yml', 'r') as f:\n    print(f.read())\n\n","type":"content","url":"/notebooks/creating-catalogs#setting-up-the-environment","position":11},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Adding Your First Data Source"},"type":"lvl2","url":"/notebooks/creating-catalogs#adding-your-first-data-source","position":12},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Adding Your First Data Source"},"content":"Intake only knows how to handle a few different data formats. To handle other formats it uses plugable drivers. To use the \n\nMesowest’s HRRR Zarr data we will use the intake-xarray package which provides a driver for reading Zarr data into \n\nXarray datasets. Drivers are installed as python packages and integrate into the Intake library. When intalled Intake creates a open_{driver} method for each driver in the package. Installing the intake-xarray package allows us to access zarr data using the open_zarr method.\n\nMesowest’s HRRR Zarr data is stored in AWS. The \n\nfile structure of the \n\nhrrrzarr S3 bucket looks like\n\ns3://hrrrzarr/sfc/yyyymmdd/yyyymmdd_hhz_anl.zarr/level/param/level\n\nwhere\n\nyyyy = four digit year\n\nmm = two digit month\n\ndd = two digit day of month\n\nhh = two digit hour of the day\n\nlevel = level of atmoshpere the data describes\n\nparam = the parameter your interested in\n\nTo load a complete dataset we need the Zarr arrays from two urls\n\ns3://hrrrzarr/sfc/yyyymmdd/yyyymmdd_hhz_anl.zarr/level/param/level\n\ns3://hrrrzarr/sfc/yyyymmdd/yyyymmdd_hhz_anl.zarr/level/param\n\nLets load surface temperature data from August 24, 2016\n\nurls = ['s3://hrrrzarr/sfc/20160824/20160824_00z_anl.zarr/surface/TMP/surface',\n           's3://hrrrzarr/sfc/20160824/20160824_00z_anl.zarr/surface/TMP']\n\nsource = intake.open_zarr(urls, storage_options={\"anon\": True})\n\nsource.name = 'hrrrzarr'\nsource.description = \"Mesowest's HRRR data. See readme source for more information.\"\nds = source.read()\nds\n\nAbove we used the storage_options argument to tell Intake how to access data on AWS. In this case we accessed the data as an anonymous user. The consolidated=True argument is given to tell \n\nXarray how to load the metadata for this source. Zarr data may contain consolidated metadata. If it does, using it can increase performance significantly.\n\nWhen you use Intake’s open_{driver} methods, it creates a catalog entry for the source. You can view the yaml using the source’s yaml method.\n\nprint(source.yaml())\n\n","type":"content","url":"/notebooks/creating-catalogs#adding-your-first-data-source","position":13},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl3":"Modifying the Source","lvl2":"Adding Your First Data Source"},"type":"lvl3","url":"/notebooks/creating-catalogs#modifying-the-source","position":14},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl3":"Modifying the Source","lvl2":"Adding Your First Data Source"},"content":"If we wanted we could add this yaml to our catalog and we could then load this data using Intake. However, there are many datasets we can load from the Zarr store with almost the same catalog entry. Making a separate entry for each would make the catalog cluttered and harder to use. Instead we will generalize this catalog entry so it applies to many datasets. Then we will create user parameters to give the catalog user the abillity to select the data they want.\n\nTo generalize the source we need Intake to dynamically generate urls pointing to the Zarr arrays based off user set parameters. We will take the source created by the open_zarr method convert it to a python dictionary and then modify it to include user parameters. We can then use those parameters to generate the urls. Intake provides Jinja templating in catalogs to make this simple. Let’s start by defining user parameters.\n\nsource_dict = yaml.load(source.yaml(), Loader=yaml.CLoader)\n\nparameters = {}\nparameters['level'] = {'description': \"Parameter specifying level in the atmosphere. Corresponds to 'Vertical Level' column in data_dictionary\",\n                       'type': 'str',\n                       'default': 'surface'}\n\nparameters['param'] = {'description': \"Specifies what parameter your dataset will contain. Corresponds to 'Parameter Short Name' in data_dictionary\",\n                       'type': 'str',\n                       'default': 'TMP'}\n\nparameters['date'] = {'description': \"Date and hour of data.\",\n                      'type': 'datetime',\n                      'default': \"2016-08-24T00:00:00\",\n                      'min': \"2016-08-24T00:00:00\"}\n\n\n\nsources = source_dict['sources']\nhrrr_zarr = sources['hrrrzarr']\nhrrr_zarr['parameters'] = parameters\n\nWith the parameters defined we can now use them to create the urls using Jinja syntax.\n\nurls = [\"s3://hrrrzarr/sfc/{{date.strftime('%Y%m%d/%Y%m%d_%Hz_anl.zarr')}}/{{level}}/{{param}}\",\n        \"s3://hrrrzarr/sfc/{{date.strftime('%Y%m%d/%Y%m%d_%Hz_anl.zarr')}}/{{level}}/{{param}}/{{level}}\"]\n\nhrrr_zarr['args']['urlpath'] = urls\n\nNow that we have a more generalized source, some of the metadata is too specific. To fix this we will just remove the data_varsection from the source’s metadata.\n\nhrrr_zarr['metadata'].pop('data_vars', None)\nprint(yaml.dump(source_dict))\n\n","type":"content","url":"/notebooks/creating-catalogs#modifying-the-source","position":15},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Documenting the Data"},"type":"lvl2","url":"/notebooks/creating-catalogs#documenting-the-data","position":16},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Documenting the Data"},"content":"We have created a data source, but it may be a little tricky to use. We need a way to let users know what options they have for the level and param user parameters we defined earlier. The inventory.csv file, created from \n\nMesowest’s HRRR Zarr Variable List, in this directory contains a table which shows what parameters are in the Zarr store and at what level in the atmosphere those parameters are available. Let’s open it as a source and add it to our source dictionary.\n\nsource = intake.open_csv('inventory.csv')\nsource.name = 'data_dictionary'\nsource.description = 'Describes the data in the hrrrzarr source'\n\nThe Vertical Level column corresponds to the level paremeter in our data source and the Parameter Short Name corresponds to the param parameter.\n\nsource\n\nThis source is almost how we want it, but the urlpath will not work after we push our catalog to Github. Intake sets the CATALOG_DIR parameter to point to whatever directory the catalog file is in. Using this parameter we can generate a url that will work even after we push the repository to Github.\n\nsources['data_dictionary'] = yaml.load(source.yaml(), \n                                       Loader=yaml.CLoader)['sources']['data_dictionary']\ndata_dictionary_args = sources['data_dictionary']['args']\ndata_dictionary_args['urlpath'] = \"{{ CATALOG_DIR }}/inventory.csv\"\nprint(yaml.dump(sources))\n\nYour source now points to a inventory.csv file in the same directory as your catalog. Be sure to copy the file into your “intake-demo” directory.\n\nNow that we have a source and a data dictionary to describe it lets add a readme to our catalog to explain how to use it and give some usage examples. This readme will also be displayed as the readme for the repository on Github. In this directory there is an example readme markdown file to use. Go ahead and copy it into the “intake-demo” directory.\n\nmd_kwargs = {\"pre\": \"<details markdown='1'>\\n<summary>README</summary>\\n\",\n             \"post\": \"\\n<br>\\nEnd of README\\n</details>\"}\nsource = intake.open_markdown('README.md', md_kwargs=md_kwargs)\nsource.name = 'readme'\nsource.description = 'Learn more about how to use this catalog'\nsource.read()\n\nThe values of pre and post in the md_kwargs dictionary are used by intake-markdown to add extra markdown before and after the markdown source. In this example we use details and summary tags to enclose the readme in a dropdown.\n\nWe will change the urlpath of this source in the same way as the data dictionary to ensure the readme loads correctly.\n\nsources['readme'] = yaml.load(source.yaml(), Loader=yaml.CLoader)['sources']['readme']\nreadme_args = sources['readme']['args']\nreadme_args['urlpath'] = \"{{ CATALOG_DIR }}/README.md\"\nprint(yaml.dump(source_dict))\n\nWith all our sources made, we will add them to the catalog, and save the catalog.\n\ncatalog['sources'] = sources\nwith open('intake-demo/catalog.yml', 'w') as f:\n    yaml.dump(catalog, f)\n\nAt this point you should have three files in your “intake-demo” directory: “catalog.yml”, “inventory.csv”, and “README.md”. All we need to do now is commit our changes and push them to Github.git add .\ngit commit -m \"initial commit\"\ngit push\n\n","type":"content","url":"/notebooks/creating-catalogs#documenting-the-data","position":17},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Testing the Catalog"},"type":"lvl2","url":"/notebooks/creating-catalogs#testing-the-catalog","position":18},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Testing the Catalog"},"content":"Now that your catalog is on Github let’s try using it. In the cell below replace the url with the url pointing to the raw catalog file on your Github account\n\ncat = intake.open_catalog('https://raw.githubusercontent.com/ProjectPythia/intake-cookbook/main/notebooks/catalog.yml')\nlist(cat)\n\ncat.readme.read()\n\ncat.data_dictionary\n\ncat.hrrrzarr.read()\n\n\n\n","type":"content","url":"/notebooks/creating-catalogs#testing-the-catalog","position":19},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/creating-catalogs#summary","position":20},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Summary"},"content":"In this tutorial we learned to create Intake catalogs and host them on Github. We learned to create sources with Intake and then modify them to make them more general. We explored a possible method for documenting data by adding a readme and data dictionary to our catalog. These guidelines will help you make your data more accessible to collaborators.\n\n","type":"content","url":"/notebooks/creating-catalogs#summary","position":21},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/creating-catalogs#resources-and-references","position":22},{"hierarchy":{"lvl1":"Creating Intake Catalogs","lvl2":"Resources and references"},"content":"Intake Documentation\n\nNOAA High-Resolution Rapid Refresh (HRRR) Data Archive\n\nHRRR Zarr Variable List\n\nAWS hrrrzarr Bucket","type":"content","url":"/notebooks/creating-catalogs#resources-and-references","position":23},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in Project Pythia’s Intake Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Introduction to Intake"},"type":"lvl1","url":"/notebooks/intake-introduction","position":0},{"hierarchy":{"lvl1":"Introduction to Intake"},"content":"\n\n","type":"content","url":"/notebooks/intake-introduction","position":1},{"hierarchy":{"lvl1":"Introduction to Intake"},"type":"lvl1","url":"/notebooks/intake-introduction#introduction-to-intake","position":2},{"hierarchy":{"lvl1":"Introduction to Intake"},"content":"\n\n\n\n","type":"content","url":"/notebooks/intake-introduction#introduction-to-intake","position":3},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/intake-introduction#overview","position":4},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Overview"},"content":"Intake is a python library that provides a consistent interface for accessing data regardless of where or how it is stored. In this notebook you will learn to:\n\nInteract with Intake catalogs\n\nUse Intake to access data stored in the cloud\n\nUse Intake to load data into Dask\n\n","type":"content","url":"/notebooks/intake-introduction#overview","position":5},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/intake-introduction#prerequisites","position":6},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nTimes and Dates in Python\n\nNecessary\n\n\n\nIntro to Xarray\n\nNecessary\n\n\n\nIntro to Cartopy\n\nHelpful\n\n\n\nUnderstanding of Zarr\n\nHelpful\n\n\n\nUnderstanding of Dask\n\nHelpful\n\n\n\nTime to learn: 45 minutes\n\n\n\n","type":"content","url":"/notebooks/intake-introduction#prerequisites","position":7},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/intake-introduction#imports","position":8},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Imports"},"content":"\n\nimport intake\nimport xarray as xr\nimport datetime as dt\nimport metpy\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport requests\nimport aiohttp\nimport intake_xarray\n\n","type":"content","url":"/notebooks/intake-introduction#imports","position":9},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Interacting with Intake Catalogs"},"type":"lvl2","url":"/notebooks/intake-introduction#interacting-with-intake-catalogs","position":10},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Interacting with Intake Catalogs"},"content":"\n\nIntake uses an object called a catalog to inform users what datasets are available to them. These catalogs can be in the form of a yaml file, a server, or a python package you install. In this example we will use a catalog to access \n\nMesowest’s HRRR data stored on AWS S3. To open a catalog use Intake’s open_catalog method with the location of the catalog as an argument. The catalog object created by calling open_catalog is iterable, so you can see what data sources are available to you by passing your catalog object as an argument to python’s list function. You can view the \n\ncatalog file used for this cookbook on Github.\n\ncat = intake.open_catalog('catalog.yml')\nlist(cat)\n\nEach of the catalog’s sources are accessible as properties of your catalog object.\n\ncat.hrrrzarr\n\n","type":"content","url":"/notebooks/intake-introduction#interacting-with-intake-catalogs","position":11},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Learning About Catalog Entries","lvl2":"Interacting with Intake Catalogs"},"type":"lvl3","url":"/notebooks/intake-introduction#learning-about-catalog-entries","position":12},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Learning About Catalog Entries","lvl2":"Interacting with Intake Catalogs"},"content":"\n\nThe first place you can look for information about a catalog source is it’s description. That is stored in the data sources’s description property.\n\ncat.hrrrzarr.description\n\nTo get a better look at a source in a Intake catalog, call it’s describe method\n\ndesc = cat.hrrrzarr.describe()\ndesc\n\nFrom this Python dictionary, there are a few things that we can learn. The container key tells us what form the data will be in when we read it. In this case it will be a \n\nXarray Dataset The user_parameters key has a list containing parameters a user can set to control what data they get. The metadata key contains an arbitrary dictionary of information specified by the catalog author. A common things to find in the metadata field are plots you can use to get a quick peak at the data.\n\n","type":"content","url":"/notebooks/intake-introduction#learning-about-catalog-entries","position":13},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Reading Data with Intake"},"type":"lvl2","url":"/notebooks/intake-introduction#reading-data-with-intake","position":14},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Reading Data with Intake"},"content":"Now that we know how to explore Intake catalogs, let’s use one to get some data. Luckily Intake makes this a really easy one-liner.\n\ncat.hrrrzarr.read()\n\nInfoIntake catalogs access data lazily. You can explore that catalog all you want, but you won't have any data until use call the read or simillar methods. The read method may take longer to run depending on your internet connection, the size of the data, and your proximity to the data center where the data is stored.\n\nWhen we look at the description of the hrrrzarr source it referenced the readme source. We can look at it using the same method. Pay attention to the projection information. It will be useful later.\n\ncat.readme.read()\n\n","type":"content","url":"/notebooks/intake-introduction#reading-data-with-intake","position":15},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Specifying User Parameters","lvl2":"Reading Data with Intake"},"type":"lvl3","url":"/notebooks/intake-introduction#specifying-user-parameters","position":16},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Specifying User Parameters","lvl2":"Reading Data with Intake"},"content":"The hrrrzarr sources in this catalog has three parameters that can be used to control what data you will read in. To list those use the user_parameters key on the description dictionary created above.\n\ndesc['user_parameters']\n\nEach user parameter can have a name, description, type, defualt, allowed, min, and max key. You can learn more about \n\nparameter definitions in Intake’s documentation. This data source contains three user parameters: date, level, and param. Each parameter’s descriptions explain what they are for. The level and param parameter allow you to select data based on level in the atmosphere and variable being measured. There allowed values correspond to values in the “Vertical Level” and “Parameter Short Name” column in the data_dictionary source repectively. The date parameter allows you to select data by date.\n\ndata_dictionary = cat.data_dictionary.read()\ndata_dictionary.query(\"`Vertical Level` == 'surface'\")[:10]\n\nLets use parameters to select surface temperature data from June 20, 2021. We can provide these parameter by passing keyword arguments to the data source.\n\nsummer_solstice_2021 = dt.datetime(2021, 6, 20)\nsource = cat.hrrrzarr(date=summer_solstice_2021, level='surface', param='TMP')\nsource.read()\n\nYour data source now points to surface temperature data taken June 20, 2021\n\n","type":"content","url":"/notebooks/intake-introduction#specifying-user-parameters","position":17},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"A More Complicated Example","lvl2":"Reading Data with Intake"},"type":"lvl3","url":"/notebooks/intake-introduction#a-more-complicated-example","position":18},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"A More Complicated Example","lvl2":"Reading Data with Intake"},"content":"\n\nMesowest provides a \n\ntutorial for reading a days worth of surface temperature HRRR data from AWS. Lets see what the same task looks like using Intake.\n\nWe will start by setting up our \n\nCartopy projection according to the information given in the readme source.\n\nprojection = ccrs.LambertConformal(central_longitude=262.5, \n                                   central_latitude=38.5, \n                                   standard_parallels=(38.5, 38.5),\n                                    globe=ccrs.Globe(semimajor_axis=6371229,\n                                                     semiminor_axis=6371229))\n\nNow lets read in the data with Intake. To do this will create a \n\ndatetime object with the date August 9, 2019. Then we will use list comprehension and timedelta objects to create a \n\ndatetime object for each hour that day. Again, using list comprehension, we will create a list of datasets using Intake. In order to concatenate our list of datasets using \n\nXarray, we need a dimension to concatenate accross. Each dataset in our list contains a time variable with an array of just one timestamp. We can promote that variable to a coordinate using the set_coords method. This may take a few minutes to run.\n\n%%time\ndate = dt.datetime(2019, 8, 10)\nhours = [date + dt.timedelta(hours=i) for i in range(24)]\ndatasets = [cat.hrrrzarr(date=hour).read().set_coords(\"time\") for hour in hours]\nds = xr.concat(datasets, dim='time', combine_attrs=\"drop_conflicts\")\nds\n\nNow our data is ready to be analyzed in the normal way using \n\nXarray.\n\navg_TMP = ds.TMP.mean(dim='time')\nfig = plt.figure(figsize=(10, 8.5))\nax = fig.add_subplot(1, 1, 1, projection=projection)\ntemp_plot = ax.contourf(avg_TMP.projection_x_coordinate, avg_TMP.projection_y_coordinate, avg_TMP)\nax.coastlines()\nfig.colorbar(temp_plot, orientation=\"horizontal\")\n\nplt.show()\n\n","type":"content","url":"/notebooks/intake-introduction#a-more-complicated-example","position":19},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Using Intake with Dask","lvl2":"Reading Data with Intake"},"type":"lvl3","url":"/notebooks/intake-introduction#using-intake-with-dask","position":20},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"Using Intake with Dask","lvl2":"Reading Data with Intake"},"content":"Often times the data we want to analyze is too big to be loaded into memory all at once on your computer. \n\nDask solves this problem by breaking up your data into smaller chunks, operating on each chunck of data, and then aggregating the results. This is usually done in parallel on a cluster system. You can use Intake to create a Dask dataset by using the to_dask method instead of the read method.\n\nds1 = cat.hrrrzarr(date=dt.datetime(2021, 1, 1)).read()\nprint(type(ds1.TMP.data))\n\nds2 = cat.hrrrzarr(date=dt.datetime(2022, 1, 1)).to_dask()\nprint(type(ds2.TMP.data))\n\nAs you can see \n\nXarray uses Dask arrays instead of \n\nNumPy arrays to hold the data when the to_dask method is used.\n\n\n\n","type":"content","url":"/notebooks/intake-introduction#using-intake-with-dask","position":21},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/intake-introduction#summary","position":22},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Summary"},"content":"Intake makes it easy to consistently access data regardless of where and how it is stored\n\nIntake catalogs contain useful information about the data they make available\n\nIntake can load data into Dask for use in parallel computing.","type":"content","url":"/notebooks/intake-introduction#summary","position":23},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/intake-introduction#whats-next","position":24},{"hierarchy":{"lvl1":"Introduction to Intake","lvl3":"What’s next?","lvl2":"Summary"},"content":"In the next notebook we will look at writing a Intake catalog and making it available on \n\nGithub.\n\n","type":"content","url":"/notebooks/intake-introduction#whats-next","position":25},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/intake-introduction#resources-and-references","position":26},{"hierarchy":{"lvl1":"Introduction to Intake","lvl2":"Resources and references"},"content":"HRRR Zarr Example Using XArray (Mesowest)\n\nIntake Documentation\n\nNOAA High-Resolution Rapid Refresh (HRRR) Data Archive\n\nHRRR Zarr Variable List","type":"content","url":"/notebooks/intake-introduction#resources-and-references","position":27}]}